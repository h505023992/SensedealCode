{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124360f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaModel,  RobertaForSequenceClassification\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import  torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cf677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =\"cpu\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11af2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A Simple Seq2Seq Dataset Implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, fact_filename, romantic_filename,funny_filename, tokenizer, add_bos_token=True, add_eos_token=True):\n",
    "        data = []\n",
    "        if fact_filename is not None:\n",
    "            with open(fact_filename,'r') as f:\n",
    "                line = f.readline()\n",
    "                while line:\n",
    "                    data.append({\"source\":\"\",\"target\":line.replace('\\n',''),\"style\":\"fact\"})\n",
    "                    line = f.readline()\n",
    "        if romantic_filename is not None:\n",
    "            with open(romantic_filename,'r') as f:\n",
    "                line = f.readline()\n",
    "                while line:\n",
    "                    data.append({\"source\":\"\",\"target\":line.replace('\\n',''),\"style\":\"romantic\"})\n",
    "                    line = f.readline() \n",
    "                    \n",
    "        if funny_filename is not None:\n",
    "            with open(funny_filename,'r') as f:\n",
    "                line = f.readline()\n",
    "                while line:\n",
    "                    data.append({\"source\":\"\",\"target\":line.replace('\\n',''),\"style\":\"funny\"})\n",
    "                    line = f.readline()    \n",
    "\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.add_bos_token = add_bos_token\n",
    "        self.add_eos_token = add_eos_token\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        target_token_ids = self.tokenizer.encode(item[\"target\"], add_special_tokens=False)\n",
    "\n",
    "        if self.add_bos_token:\n",
    "            target_token_ids.insert(0, self.tokenizer.bos_token_id)\n",
    "\n",
    "        if self.add_eos_token:\n",
    "            target_token_ids.append(self.tokenizer.eos_token_id)\n",
    "\n",
    "\n",
    "        item[\"target_token_ids\"] = torch.LongTensor(target_token_ids)\n",
    "        \n",
    "        if item[\"style\"]=='fact':\n",
    "            item[\"source_token_ids\"] = [1,0,0]\n",
    "        elif item[\"style\"]=='romantic':\n",
    "            item[\"source_token_ids\"] = [0, 1, 0]\n",
    "        elif item[\"style\"]=='funny':\n",
    "            item[\"source_token_ids\"] = [0, 0, 1]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        new_batch = {}\n",
    "        new_batch[\"source_token_ids\"] = torch.tensor([item[\"source_token_ids\"] for item in batch])\n",
    "        new_batch[\"target_token_ids\"] = pad_sequence(\n",
    "            [item[\"target_token_ids\"] for item in batch], batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        new_batch[\"style\"] = [item[\"style\"] for item in batch]\n",
    "        return new_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54874d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c132ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_filename = \"./funny-GEN.txt\"\n",
    "romantic_filename = \"./romantic-GEN.txt\"\n",
    "funny_filename = \"./funny-GEN.txt\"\n",
    "gen_dataset = Seq2SeqDataset(fact_filename=fact_filename,romantic_filename=romantic_filename,funny_filename=funny_filename,tokenizer=tokenizer)\n",
    "gen_dataloader = DataLoader(\n",
    "            gen_dataset, batch_size=batch_size, shuffle=True, collate_fn=gen_dataset .collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f84d4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact_filename = \"../StyleCaption/fact-test.txt\"\n",
    "# romantic_filename = \"../StyleCaption/romantic-test.txt\"\n",
    "# funny_filename = \"../StyleCaption/funny-test.txt\"\n",
    "# gen_dataset = Seq2SeqDataset(fact_filename,romantic_filename,funny_filename , tokenizer)\n",
    "# gen_dataloader = DataLoader(\n",
    "#             test_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02e4b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pth = \"/home/hqh/Triple-Gan/classify.pth\"\n",
    "model = torch.load(class_pth, map_location=device)\n",
    "device =\"cpu\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a24ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在验证集上,正确个数：809,总个数：1536,准确率:0.5266926884651184,fact:0.361328125,romantic:0.677734375,funny:0.541015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    epoch_num = 0 \n",
    "    epoch_real= 0\n",
    "    fact_epoch=0\n",
    "    romantic_epoch = 0\n",
    "    funny_epoch=0\n",
    "    for batch in tqdm.tqdm(gen_dataloader):\n",
    "        sequence = batch['target_token_ids'].to(device)\n",
    "        label_onehot = batch['source_token_ids'] # n*3,tensor\n",
    "        label = torch.argmax(label_onehot,dim=-1).to(device) # n tensor\n",
    "        sequence_logits = model(sequence).logits\n",
    "        #打印\n",
    "        pred_true = torch.argmax(sequence_logits,dim=-1) == label\n",
    "        batch_real = ( pred_true).sum()\n",
    "        batch_num = len(label)\n",
    "        epoch_real += batch_real\n",
    "        epoch_num += len(label)\n",
    "        #分门别类\n",
    "        fact_epoch +=  pred_true[(label==0).nonzero().reshape(-1)].sum()\n",
    "        romantic_epoch +=  pred_true[(label==1).nonzero().reshape(-1)].sum()\n",
    "        funny_epoch +=  pred_true[(label==2).nonzero().reshape(-1)].sum()\n",
    "    acc_rate = epoch_real/epoch_num\n",
    "    print(\"在验证集上,正确个数：{},总个数：{},准确率:{},fact:{},romantic:{},funny:{}\"\n",
    "      .format(epoch_real,epoch_num,acc_rate,fact_epoch*3/epoch_num,romantic_epoch*3/epoch_num,funny_epoch*3/epoch_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbce2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
